{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 200)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "from matplotlib_venn import venn2\n",
    "import re\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from fpdf import FPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entradas\n",
    "\n",
    "* LOI.csv\n",
    "* results.csv (resultado do SDG)\n",
    "* revList.csv (do SDG)\n",
    "* soot-results.csv (resultado do Static Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_method_name(signature):\n",
    "    method_full_name = signature.split('(')[0]\n",
    "    method_name = method_full_name.split('.')[-1]\n",
    "    return method_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name of the CSV file\n",
    "file_name = 'revList.csv'\n",
    "\n",
    "# List to store the DataFrames\n",
    "found_files = []\n",
    "\n",
    "# Open the CSV file for reading\n",
    "with open(file_name, mode='r', newline='', encoding='utf-8') as file:\n",
    "    # Create a CSV reader\n",
    "    csv_reader = csv.reader(file, delimiter=';')\n",
    "    \n",
    "    # Skip the first line (header)\n",
    "    next(csv_reader)\n",
    "    cont = 0\n",
    "    # Read the remaining lines and process each line\n",
    "    for row in csv_reader:\n",
    "        project = row[0]\n",
    "        merge_commit = row[1]\n",
    "        class_name = row[2]\n",
    "        method = row[3]\n",
    "        # left_modification = row[4]\n",
    "        # has_build = row[5]\n",
    "        # left_deletion = row[6]\n",
    "        # right_modification = row[7]\n",
    "        # right_deletion = row[8]\n",
    "        # realistic_case_path = row[9]\n",
    "\n",
    "        # Generate path\n",
    "        parts = class_name.split('.')\n",
    "        class_name = parts.pop()\n",
    "        class_path = '.'.join(parts).replace(\".\", \"/\")\n",
    "        method_name = extract_method_name(method)\n",
    "        \n",
    "        path_file = f\"joana/reports/{project}/{merge_commit}/{class_path}/{class_name}/{method_name}/executionSummary.csv\"\n",
    "        \n",
    "        if os.path.exists(path_file):\n",
    "            try:\n",
    "                df = pd.read_csv(path_file, sep=';')\n",
    "                # Add context columns to the DataFrame\n",
    "                df['project'] = project\n",
    "                df['merge commit'] = merge_commit\n",
    "                df['class'] = class_name\n",
    "                df['original method'] = method\n",
    "\n",
    "            except:\n",
    "                print(f\"Error: The file '{path_file}' is empty.\")\n",
    "                data = {\n",
    "                'project': project,\n",
    "                'merge commit': merge_commit,\n",
    "                'class': class_name,\n",
    "                'original method': [method]\n",
    "                }\n",
    "                \n",
    "                df = pd.DataFrame(data)\n",
    "\n",
    "        else:\n",
    "            print(path_file)\n",
    "            cont+=1\n",
    "            data = {\n",
    "                'project': project,\n",
    "                'merge commit': merge_commit,\n",
    "                'class': class_name,\n",
    "                'original method': [method]\n",
    "            }\n",
    "            \n",
    "            df = pd.DataFrame(data)\n",
    "        print(df.columns)\n",
    "        # Reorder columns to have new columns at the beginning\n",
    "        columns_order = ['project', 'merge commit', 'class', 'original method'] + [col for col in df.columns if col not in ['project', 'merge commit', 'class', 'original method']]\n",
    "        df = df[columns_order]\n",
    "        found_files.append(df)\n",
    "\n",
    "    print(\"Não existem\", cont)\n",
    "    # Check if there are DataFrames to concatenate\n",
    "    if len(found_files) > 0:\n",
    "        # Concatenate all DataFrames, keeping all rows and columns\n",
    "        merged_file = pd.concat(found_files, ignore_index=True, sort=False)\n",
    "\n",
    "        merged_file = merged_file.drop(columns=['Method'])\n",
    "\n",
    "        # Save the result to a new CSV file with ';' as separator\n",
    "        merged_file.to_csv('output/files/merged_file.csv', index=False, sep=';')\n",
    "        print(\"Files merged successfully! File saved as 'output/files/merged_file.csv'.\")\n",
    "    else:\n",
    "        print(\"No file was found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportAnalysis:\n",
    "\n",
    "    def __init__(self, path_result, path_ground_truth):\n",
    "        self.soot_results = pd.read_csv(path_result, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "        self.loi = pd.read_csv(path_ground_truth, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "\n",
    "        self.generate_results()\n",
    "\n",
    "    def get_method_name(self, method_declaration):\n",
    "        match = re.search(r'\\.([a-zA-Z_][a-zA-Z0-9_]*)\\(', method_declaration)\n",
    "        if match:\n",
    "            method_name = match.group(1)\n",
    "            print(\"Method name:\", method_name)\n",
    "        else:\n",
    "            print(\"Method name not found.\")\n",
    "\n",
    "    def get_loi(self, project, class_name, method, merge_commit):\n",
    "        df = pd.read_csv(\"LOI.csv\", delimiter=';')\n",
    "        print(method)\n",
    "        # Encontrar o índice do ponto final e do parêntese\n",
    "        dot_index = method.rfind('.')\n",
    "        paren_index = method.find('(')\n",
    "\n",
    "        method_name = \"\"\n",
    "\n",
    "        # Extrair o nome do método\n",
    "        if dot_index != -1 and paren_index != -1:\n",
    "            method_name = method[dot_index + 1:paren_index]\n",
    "\n",
    "        value_LOI = (\"\", \"\")\n",
    "        \n",
    "        for project_l, class_name_l, method_l, merge_commit_l, LOI, original_sample in zip(\n",
    "            df['Project'], \n",
    "            df['Class Name'], \n",
    "            df['Method or field declaration changed by the two merged branches'], \n",
    "            df['Merge Commit'], \n",
    "            df['Locally Observable Interference'],\n",
    "            df['Original Sample'],\n",
    "        ):\n",
    "            if (project_l == project and \n",
    "                class_name in class_name_l  and \n",
    "                method_name in method_l and \n",
    "                merge_commit_l == merge_commit):\n",
    "                \n",
    "                value_LOI = (LOI, original_sample)\n",
    "\n",
    "                break  # Para parar no primeiro match encontrado\n",
    "\n",
    "        return value_LOI\n",
    "\n",
    "    def calculate_matrix_loi(self, columns):\n",
    "        results = []\n",
    "        loi_list = []\n",
    "        original_sample_list = []\n",
    "        info_LOI = ['project', 'class', 'original method', 'merge commit']\n",
    "        \n",
    "        # Limpar espaços em branco nos nomes das colunas\n",
    "        self.soot_results.columns = self.soot_results.columns.str.strip()\n",
    "        print(\"Colunas:\", self.soot_results.columns)\n",
    "        for index, row in self.soot_results.iterrows():\n",
    "            value = row['HasSourcedAndSink']\n",
    "                    \n",
    "            values_LOI = [row[column] for column in info_LOI if column in row]\n",
    "            print(\"Colunas: \", values_LOI)\n",
    "            (loi_actual, original_sample) = self.get_loi(*values_LOI)\n",
    "            \n",
    "            loi_list.append(loi_actual)\n",
    "            original_sample_list.append(original_sample)\n",
    "\n",
    "            result = \"-\"\n",
    "            # Determinar o resultado\n",
    "            if \"Yes\" in str(value) and \"Yes\" in loi_actual:\n",
    "                result = \"TRUE POSITIVE\"\n",
    "            elif \"No\" in str(value) and \"No\" in loi_actual:\n",
    "                result = \"TRUE NEGATIVE\"\n",
    "            elif \"No\" in str(value) and \"Yes\" in loi_actual:\n",
    "                result = \"FALSE NEGATIVE\"\n",
    "            elif \"Yes\" in str(value) and \"No\" in loi_actual:\n",
    "                result = \"FALSE POSITIVE\"\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "        df = pd.read_csv('output/files/merged_file.csv', sep=';')\n",
    "        df['LOI'] = loi_list\n",
    "        df['Original Sample'] = original_sample_list\n",
    "        df['result'] = results\n",
    "\n",
    "        # Salvar o novo DataFrame em um novo arquivo CSV\n",
    "        new_csv_path = 'output/results/results.csv'\n",
    "        df.to_csv(new_csv_path, sep=';', index=False)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def generate_results(self):\n",
    "\n",
    "        print(\"Generating results...\")\n",
    "\n",
    "        FP,TP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "        list_columns = self.soot_results.columns.tolist()\n",
    "\n",
    "        result_matrix = self.calculate_matrix_loi(list_columns)\n",
    "\n",
    "        for elem, count in Counter(result_matrix).items():\n",
    "            if (elem == 'FALSE POSITIVE'):\n",
    "                FP = count\n",
    "            if (elem == 'FALSE NEGATIVE'):\n",
    "                FN = count\n",
    "            if (elem == 'TRUE POSITIVE'):\n",
    "                TP = count\n",
    "            if (elem == 'TRUE NEGATIVE'):\n",
    "                TN = count\n",
    "\n",
    "        sensitivity = 0 if ((TP + FN) == 0) else (TP / (TP + FN))\n",
    "        precision = 0 if ((TP + FP) == 0) else (TP / (TP + FP))\n",
    "        f1_score = 0 if ((2*TP + FP + FN) == 0) else (2*TP / (2*TP + FP + FN))\n",
    "        accuracy = 0 if ((FP + TP + TN + FN) == 0) else ((TP + TN) / (FP + TP + TN + FN))\n",
    "\n",
    "        df = pd.read_csv(\"output/results/results.csv\", sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "       \n",
    "        fail_results = df['result'].eq(\"-\").sum()\n",
    "        total = len(df)\n",
    "\n",
    "        # variable pdf\n",
    "        pdf = FPDF()\n",
    "\n",
    "        # add a page\n",
    "        pdf.add_page()\n",
    "\n",
    "        # set style and size of font\n",
    "        # that you want in the pdf\n",
    "        pdf.set_font(\"Arial\", size = 15)\n",
    "\n",
    "        # create a cell\n",
    "        pdf.cell(200, 10, txt = \"Results for execution\",\n",
    "                 ln = 1, align = 'C')\n",
    "    \n",
    "        pdf.cell(200, 10, txt = (\"Precision: \"+str(round(precision, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"Recall: \"+str(round(sensitivity, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"F1 Score: \"+str(round(f1_score, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"Accuracy: \"+str(round(accuracy, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"False Positives: \"+str(FP)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"False Negatives: \"+str(FN)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"True Positives: \"+str(TP)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"True Negatives: \"+str(TN)),\n",
    "                 ln = 2, align = 'L')\n",
    "        \n",
    "        pdf.cell(200, 10, txt = (f\"Total produzed: {total-fail_results} out of {total} units\"),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        cm = np.array([[TP,  FP], [FN, TN]])\n",
    "        normalize = False\n",
    "        target_names = ['Actually Positive', ' Actually Negative']\n",
    "        target_names2 = ['Predicted Positive', ' Predicted Negative']\n",
    "        title = \"Confusion Matrix\"\n",
    "\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.colorbar()\n",
    "\n",
    "        if target_names is not None:\n",
    "            tick_marks = np.arange(len(target_names))\n",
    "            plt.xticks(tick_marks, target_names, fontsize=16)\n",
    "            plt.yticks(tick_marks, target_names2, fontsize=16)\n",
    "\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"yellow\" if cm[i, j] > thresh else \"black\", fontsize=23)\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"yellow\" if cm[i, j] > thresh else \"black\", fontsize=23)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(\"confusion_matrix.jpg\")\n",
    "\n",
    "        pdf.image(\"confusion_matrix.jpg\", x = None, y = None, w = 160, h = 110, type = 'jpg', link = 'confusion_matrix.jpg')\n",
    "\n",
    "        # Save the pdf with name .pdf\n",
    "        pdf.output(\"output/results/results.pdf\")\n",
    "        \n",
    "        print(\"Results in output/results/results.pdf\")\n",
    "\n",
    "path_ground_truth = \"LOI.csv\"\n",
    "path_result = 'output/files/merged_file.csv'\n",
    "\n",
    "print(\"Reading analyses execution results...\")\n",
    "\n",
    "ReportAnalysis(path_result, path_ground_truth)\n",
    "\n",
    "#project, class_name, method, merge_commit\n",
    "#Colunas:  ['druid', 'S3SegmentPusher', '05168808c278c080c59c19e858d9471b316cd1f5']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_result = 'output/files/merged_file.csv'\n",
    "\n",
    "print(\"Reading analyses execution results...\")\n",
    "soot_results = pd.read_csv(path_result, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "\n",
    "soot_results.columns = soot_results.columns.str.strip()\n",
    "list_time_seconds = []\n",
    "\n",
    "for index, row in soot_results.iterrows():\n",
    "    value = row['Time (ms)']\n",
    "    try:\n",
    "        # Ignora valores que não são numéricos, como ' -'\n",
    "        if str(value) not in ['', '-', 'NaN', 'nan']:\n",
    "            list_time_seconds.append(float(value) / 1000)\n",
    "    except ValueError:\n",
    "        continue\n",
    "       \n",
    "print(list_time_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Exemplo de classe que utiliza a função plot_by_variable\n",
    "class Plotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_by_variable(self, leg1, leg_x, time_list1):\n",
    "        # Define o tamanho da figura\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "        # Dados\n",
    "        data_x = [time_list1]\n",
    "\n",
    "        # Cores para os gráficos\n",
    "        boxplot_color = 'yellowgreen'\n",
    "        violin_color = 'thistle'\n",
    "        scatter_color = 'tomato'\n",
    "\n",
    "        # Boxplot\n",
    "        bp = ax.boxplot(data_x, patch_artist=True, vert=False, positions=[1], widths=0.6)\n",
    "        for patch in bp['boxes']:\n",
    "            patch.set_facecolor(boxplot_color)\n",
    "            patch.set_alpha(0.4)\n",
    "\n",
    "        # Violinplot\n",
    "        vp = ax.violinplot(data_x, points=500, showmeans=True, showextrema=True, showmedians=False, vert=False)\n",
    "        for b in vp['bodies']:\n",
    "            b.set_color(violin_color)\n",
    "            b.set_alpha(0.6)\n",
    "\n",
    "        # Scatterplot\n",
    "        features = data_x[0]\n",
    "        y = np.full(len(features), 1)  # Usando apenas 1 para a posição no eixo Y\n",
    "        jitter = np.random.uniform(low=-0.1, high=0.1, size=len(features))\n",
    "        ax.scatter(features + jitter, y, s=15, c=scatter_color, alpha=0.7, edgecolor='k')\n",
    "\n",
    "        # Configurações do gráfico\n",
    "        ax.set_yticks([1])\n",
    "        ax.grid(False)\n",
    "        ax.set_yticklabels([leg1])\n",
    "        ax.set_xlabel(leg_x)\n",
    "        ax.set_title(\"Results by time (s)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"rain_cloud_time_sdg.jpg\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "# Criar uma instância da classe ExamplePlotter\n",
    "plotter = Plotter()\n",
    "\n",
    "# Nome da variável a ser plotada\n",
    "y = \"SDG\"\n",
    "x = \"Values (seconds)\"\n",
    "\n",
    "# Chamar a função para plotar o gráfico\n",
    "plotter.plot_by_variable(y, x, list_time_seconds)\n",
    "\n",
    "#time_list = [random.uniform(0.5, 3.5) for _ in range(100)]\n",
    "#plotter.plot_by_variable(y, x, time_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def converter_segundos(tempo_em_segundos):\n",
    "    horas = int(tempo_em_segundos // 3600)\n",
    "    minutos = int((tempo_em_segundos % 3600) // 60)\n",
    "    segundos = tempo_em_segundos % 60\n",
    "    return horas, minutos, segundos\n",
    "\n",
    "tempo_em_segundos = max(list_time_seconds)\n",
    "horas, minutos, segundos = converter_segundos(tempo_em_segundos)\n",
    "\n",
    "print(f\"{horas} horas, {minutos} minutos e {segundos:.3f} segundos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Exemplo de classe que utiliza a função plot_by_variable\n",
    "class Plotter:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def plot_by_variable(self, leg1, leg2, leg_x, time_list1, time_list2):\n",
    "        # Define o tamanho da figura\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "        # Dados\n",
    "        data_x = [time_list1, time_list2]\n",
    "\n",
    "        # Cores para os gráficos\n",
    "        boxplots_colors = ['yellowgreen', 'lightblue']\n",
    "        violin_colors = ['thistle', 'lightcyan']\n",
    "        scatter_colors = ['tomato', 'darksalmon']\n",
    "\n",
    "        # Boxplot\n",
    "        bp = ax.boxplot(data_x, patch_artist=True, vert=False, positions=[1, 2], widths=0.6)\n",
    "        for patch, color in zip(bp['boxes'], boxplots_colors):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.4)\n",
    "\n",
    "        # Violinplot\n",
    "        vp = ax.violinplot(data_x, points=500, showmeans=True, showextrema=True, showmedians=False, vert=False)\n",
    "        for idx, b in enumerate(vp['bodies']):\n",
    "            b.set_color(violin_colors[idx])\n",
    "            b.set_alpha(0.6)\n",
    "\n",
    "        # Scatterplot\n",
    "        for idx, features in enumerate(data_x):\n",
    "            y = np.full(len(features), idx + 1)\n",
    "            jitter = np.random.uniform(low=-0.1, high=0.1, size=len(features))\n",
    "            ax.scatter(features + jitter, y, s=15, c=scatter_colors[idx], alpha=0.7, edgecolor='k')\n",
    "\n",
    "        # Configurações do gráfico\n",
    "        ax.set_yticks([1, 2])\n",
    "        ax.grid(False)\n",
    "        ax.set_yticklabels([leg1, leg2])\n",
    "        ax.set_xlabel(leg_x)\n",
    "        ax.set_title(\"Results by time (s)\")\n",
    "        ax.legend(loc='upper right', bbox_to_anchor=(1.1, 1))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"rain_cloud_time_sdg_sam.jpg\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "       \n",
    "# Criar uma instância da classe Plotter\n",
    "plotter = Plotter()\n",
    "\n",
    "# Gerar duas listas de tempos de exemplo (em segundos)\n",
    "random.seed(42)  # Para reprodutibilidade\n",
    "time_list1 = [random.uniform(0.5, 3.5) for _ in range(100)]\n",
    "time_list2 = [random.uniform(1.0, 4.0) for _ in range(100)]\n",
    "\n",
    "# Nome da variável a ser plotada\n",
    "variable = \"Execution Time\"\n",
    "\n",
    "# Chamar a função para plotar o gráfico\n",
    "plotter.plot_by_variable(\"Static Analyses\", \"SDG\", \"Values (seconds)\", time_list1, time_list2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "from fpdf import FPDF\n",
    "\n",
    "class ReportAnalysis:\n",
    "\n",
    "    def __init__(self, path_result, path_ground_truth):\n",
    "        self.soot_results = pd.read_csv(path_result, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "        self.loi = pd.read_csv(path_ground_truth, sep=';', encoding='latin-1', on_bad_lines='skip', low_memory=False)\n",
    "\n",
    "        self.generate_results()\n",
    "\n",
    "    def get_loi(self, project, class_name,  method, merge_commit):\n",
    "\n",
    "        filter_scenario = (self.loi['Project'] == str(project)) & (self.loi['Merge Commit'] == str(merge_commit)) & (self.loi['Class Name'] == str(class_name)) & (self.loi['Method or field declaration changed by the two merged branches'] == str(method))\n",
    "        value_LOI = \"\"\n",
    "\n",
    "        if filter_scenario.any():\n",
    "            value_LOI = self.loi.loc[filter_scenario, 'Locally Observable Interference'].values[0]\n",
    "\n",
    "        return value_LOI\n",
    "\n",
    "    def calculate_matrix_loi(self, columns):\n",
    "        results = []\n",
    "        loi_list = []\n",
    "        info_LOI = ['project', 'class', 'method', 'merge commit']\n",
    "\n",
    "        for index, row in self.soot_results.iterrows():\n",
    "            list_values = self.soot_results.columns.tolist()\n",
    "            remove_columns = ['project', 'class', 'method', 'merge commit', 'Time']\n",
    "            list_values = [coluna for coluna in list_values if coluna not in remove_columns]\n",
    "            values = [row[column] for column in list_values]\n",
    "\n",
    "            values_LOI = [row[column] for column in info_LOI]\n",
    "\n",
    "            loi_actual = self.get_loi(*values_LOI)\n",
    "            loi_list.append(loi_actual)\n",
    "            or_value = any(str(value).lower() != 'false' for value in values)\n",
    "\n",
    "            result = \"\"\n",
    "            if or_value == True and loi_actual == 'Yes':\n",
    "                result = \"TRUE POSITIVE\"\n",
    "            elif or_value == False and loi_actual == 'No':\n",
    "                result = \"TRUE NEGATIVE\"\n",
    "            elif or_value == False and loi_actual == 'Yes':\n",
    "                result = \"FALSE NEGATIVE\"\n",
    "            elif or_value == True and loi_actual == 'No':\n",
    "                result = \"FALSE POSITIVE\"\n",
    "            results.append(result)\n",
    "\n",
    "\n",
    "        self.soot_results['LOI'] = loi_list\n",
    "        self.soot_results['result'] = results\n",
    "\n",
    "        self.soot_results.to_csv('output/files/result_static.csv', sep=';', index=False)\n",
    "\n",
    "        return results\n",
    "            \n",
    "    def generate_results(self):\n",
    "\n",
    "        print(\"Generating results...\")\n",
    "\n",
    "        FP,TP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "        list_columns = self.soot_results.columns.tolist()\n",
    "\n",
    "        result_matrix = self.calculate_matrix_loi(list_columns)\n",
    "\n",
    "        for elem, count in Counter(result_matrix).items():\n",
    "            if (elem == 'FALSE POSITIVE'):\n",
    "                FP = count\n",
    "            if (elem == 'FALSE NEGATIVE'):\n",
    "                FN = count\n",
    "            if (elem == 'TRUE POSITIVE'):\n",
    "                TP = count\n",
    "            if (elem == 'TRUE NEGATIVE'):\n",
    "                TN = count\n",
    "\n",
    "        sensitivity = 0 if ((TP + FN) == 0) else (TP / (TP + FN))\n",
    "        precision = 0 if ((TP + FP) == 0) else (TP / (TP + FP))\n",
    "        f1_score = 0 if ((2*TP + FP + FN) == 0) else (2*TP / (2*TP + FP + FN))\n",
    "        accuracy = 0 if ((FP + TP + TN + FN) == 0) else ((TP + TN) / (FP + TP + TN + FN))\n",
    "\n",
    "        # variable pdf\n",
    "        pdf = FPDF()\n",
    "\n",
    "        # add a page\n",
    "        pdf.add_page()\n",
    "\n",
    "        # set style and size of font\n",
    "        # that you want in the pdf\n",
    "        pdf.set_font(\"Arial\", size = 15)\n",
    "\n",
    "        # create a cell\n",
    "        pdf.cell(200, 10, txt = \"Results for execution\",\n",
    "                 ln = 1, align = 'C')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"Precision: \"+str(round(precision, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"Recall: \"+str(round(sensitivity, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"F1 Score: \"+str(round(f1_score, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"Accuracy: \"+str(round(accuracy, 2))),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"False Positives: \"+str(FP)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"False Negatives: \"+str(FN)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"True Positives: \"+str(TP)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        pdf.cell(200, 10, txt = (\"True Negatives: \"+str(TN)),\n",
    "                 ln = 2, align = 'L')\n",
    "\n",
    "        cm = np.array([[TP,  FP], [FN, TN]])\n",
    "        normalize = False\n",
    "        target_names = ['Actually Positive', ' Actually Negative']\n",
    "        target_names2 = ['Predicted Positive', ' Predicted Negative']\n",
    "        title = \"Confusion Matrix\"\n",
    "\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "        plt.title(title, fontsize=16)\n",
    "        plt.colorbar()\n",
    "\n",
    "        if target_names is not None:\n",
    "            tick_marks = np.arange(len(target_names))\n",
    "            plt.xticks(tick_marks, target_names, fontsize=16)\n",
    "            plt.yticks(tick_marks, target_names2, fontsize=16)\n",
    "\n",
    "        if normalize:\n",
    "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "        thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "            if normalize:\n",
    "                plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"yellow\" if cm[i, j] > thresh else \"black\", fontsize=23)\n",
    "            else:\n",
    "                plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                         horizontalalignment=\"center\",\n",
    "                         color=\"yellow\" if cm[i, j] > thresh else \"black\", fontsize=23)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.savefig(\"confusion_matrix.jpg\")\n",
    "\n",
    "        pdf.image(\"confusion_matrix.jpg\", x = None, y = None, w = 160, h = 110, type = 'jpg', link = 'confusion_matrix.jpg')\n",
    "\n",
    "        # Save the pdf with name .pdf\n",
    "        pdf.output(\"output/files/results_static.pdf\")\n",
    "    \n",
    "        print(\"Results in output/files/results_static.pdf\")\n",
    "\n",
    "\n",
    "print(\"Reading analyses execution results...\")\n",
    "\n",
    "path_ground_truth = \"LOI.csv\"\n",
    "path_result = 'soot-results.csv'\n",
    "list_calculate = ['Confluence Inter', 'OA Inter', 'left right DFP-Inter', 'right left DFP-Inter', 'left right PDG', 'right left PDG']\n",
    "print(\"Reading analyses execution results...\")\n",
    "\n",
    "ReportAnalysis(path_result, path_ground_truth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"output/results/results.csv\", sep=\";\")\n",
    "\n",
    "df1[\"method\"] = df1[\"original method\"].apply(\n",
    "    lambda x: re.search(r\"\\.([a-zA-Z0-9_]+)\\(\", x.strip()).group(1) \n",
    "    if isinstance(x, str) and re.search(r\"\\.([a-zA-Z0-9_]+)\\(\", x.strip()) else \"\"\n",
    ")\n",
    "\n",
    "method_column = df1.pop(\"method\")  # Remover a coluna 'method'\n",
    "df1.insert(df1.columns.get_loc(\"original method\"), \"method\", method_column)  # Inserir na posição correta\n",
    "\n",
    "df1 = df1.drop(columns=[\"original method\"])\n",
    "\n",
    "df1.to_csv(\"output/files/df_sdg.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"output/files/result_static.csv\", sep=\";\")\n",
    "\n",
    "df1[\"method\"] = df1[\"method\"].apply(\n",
    "    lambda x: re.match(r\"([a-zA-Z0-9_]+)\", x).group(1) if isinstance(x, str) else \"\"\n",
    ")\n",
    "\n",
    "df1[\"class\"] = df1[\"class\"].apply(\n",
    "    lambda x: x.split('.')[-1] if isinstance(x, str) else \"\"\n",
    ")\n",
    "\n",
    "df1.to_csv(\"output/files/df_static.csv\", sep=\";\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_from_df(df, project, merge_commit, class_name, method_name):\n",
    "    matching_row = df[\n",
    "        (df[\"project\"].str.contains(project, na=False)) &\n",
    "        (df[\"merge commit\"].str.contains(merge_commit, na=False)) &\n",
    "        (df[\"class\"].str.contains(class_name, na=False)) &\n",
    "        (df[\"method\"].str.contains(method_name, na=False))\n",
    "    ]\n",
    "    \n",
    "    return matching_row[\"result\"].iloc[0] if not matching_row.empty else None\n",
    "\n",
    "df1 = pd.read_csv(\"output/files/df_sdg.csv\", sep=\";\")\n",
    "df2 = pd.read_csv(\"output/files/df_static.csv\", sep=\";\")\n",
    "\n",
    "resultados = []\n",
    "\n",
    "sdg_exclusivos = {\"TRUE POSITIVE\": 0, \"FALSE POSITIVE\": 0, \"TRUE NEGATIVE\": 0, \"FALSE NEGATIVE\": 0}\n",
    "sa_exclusivos = {\"TRUE POSITIVE\": 0, \"FALSE POSITIVE\": 0, \"TRUE NEGATIVE\": 0, \"FALSE NEGATIVE\": 0}\n",
    "\n",
    "sdg_counts = {\"TRUE POSITIVE\": 0, \"FALSE POSITIVE\": 0, \"TRUE NEGATIVE\": 0, \"FALSE NEGATIVE\": 0}\n",
    "sa_counts = {\"TRUE POSITIVE\": 0, \"FALSE POSITIVE\": 0, \"TRUE NEGATIVE\": 0, \"FALSE NEGATIVE\": 0}\n",
    "\n",
    "equals_counts = {\"TRUE POSITIVE\": 0, \"FALSE POSITIVE\": 0, \"TRUE NEGATIVE\": 0, \"FALSE NEGATIVE\": 0}\n",
    "\n",
    "for _, row in df1.iterrows():\n",
    "    project = row[\"project\"]\n",
    "    merge_commit = row[\"merge commit\"]\n",
    "    class_name = row[\"class\"]\n",
    "    method_name = row[\"method\"]\n",
    "    result_sdg = row[\"result\"]\n",
    "\n",
    "    if result_sdg != \"-\":  # ignorar casos sem resultado\n",
    "        result_sa = get_result_from_df(df2, project, merge_commit, class_name, method_name)\n",
    "        is_equal = result_sdg == result_sa\n",
    "        resultados.append((project, merge_commit, class_name, method_name, result_sdg, result_sa, is_equal))\n",
    "\n",
    "        if result_sdg in sdg_counts:\n",
    "            sdg_counts[result_sdg] += 1\n",
    "        if result_sa in sa_counts:\n",
    "            sa_counts[result_sa] += 1\n",
    "\n",
    "        if result_sdg != result_sa:\n",
    "            if result_sdg in sdg_exclusivos:\n",
    "                sdg_exclusivos[result_sdg] += 1\n",
    "            if result_sa in sa_exclusivos:\n",
    "                sa_exclusivos[result_sa] += 1\n",
    "        else:\n",
    "            equals_counts[result_sdg] += 1\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(resultados, columns=[\"project\", \"merge commit\", \"class\", \"method\", \"result_sdg\", \"result_sa\", \"is_equal\"])\n",
    "\n",
    "iguais = result_df[\"is_equal\"].sum()\n",
    "diferentes = len(result_df) - iguais\n",
    "\n",
    "def calcular_metricas(contagens):\n",
    "    TP = contagens.get(\"TRUE POSITIVE\", 0)\n",
    "    FP = contagens.get(\"FALSE POSITIVE\", 0)\n",
    "    TN = contagens.get(\"TRUE NEGATIVE\", 0)\n",
    "    FN = contagens.get(\"FALSE NEGATIVE\", 0)\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Precision\": round(precision, 4),\n",
    "        \"Recall\": round(recall, 4),\n",
    "        \"F1 Score\": round(f1_score, 4),\n",
    "        \"Accuracy\": round(accuracy, 4)\n",
    "    }\n",
    "\n",
    "metricas_sdg = calcular_metricas(sdg_counts)\n",
    "metricas_sa = calcular_metricas(sa_counts)\n",
    "\n",
    "result_df.to_csv(\"output/results/comparison_results.csv\", sep=\";\", index=False)\n",
    "\n",
    "sdg_set = set(sdg_counts.keys())\n",
    "sa_set = set(sa_counts.keys())\n",
    "\n",
    "venn_file = \"output/results/venn_diagram.png\"\n",
    "plt.figure(figsize=(6, 6))\n",
    "#venn = venn2(subsets=(diferentes, diferentes, iguais), set_labels=(\"SDG\", \"SA\"))\n",
    "venn = venn2(subsets=(diferentes, diferentes, iguais), set_labels=(\"SDG\", \"SA\"),\n",
    "             set_colors=('skyblue', 'lightgreen'), alpha=0.7)\n",
    "\n",
    "venn.get_label_by_id(\"10\").set_text(f\"{diferentes}\\nExclusivos\\nSDG\")\n",
    "venn.get_label_by_id(\"01\").set_text(f\"{diferentes}\\nExclusivos\\nSA\")\n",
    "venn.get_label_by_id(\"11\").set_text(f\"{iguais}\\nIguais\")\n",
    "\n",
    "plt.title(\"Diagrama de Venn: Comparação entre SDG e SA\")\n",
    "plt.savefig(venn_file)\n",
    "\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "pdf.cell(200, 10, txt=f\"Comparação entre SDG e SA ({len(result_df)} units)\", ln=True, align=\"C\")\n",
    "pdf.ln(10)\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "\n",
    "pdf.set_font(\"Arial\", 'B', 10)\n",
    "pdf.cell(35, 10, \"Resultado\", border=1, align=\"C\")\n",
    "pdf.cell(35, 10, \"Total SDG\", border=1, align=\"C\")\n",
    "pdf.cell(35, 10, \"Total SA\", border=1, align=\"C\")\n",
    "pdf.cell(35, 10, \"Exclusivos SDG\", border=1, align=\"C\")\n",
    "pdf.cell(35, 10, \"Exclusivos SA\", border=1, align=\"C\")\n",
    "pdf.cell(20, 10, \"Iguais\", border=1, align=\"C\")\n",
    "pdf.ln()\n",
    "\n",
    "pdf.set_font(\"Arial\", size=10)\n",
    "\n",
    "all_metrics = set(sdg_counts.keys()).union(set(sa_counts.keys()))\n",
    "for metric in all_metrics:\n",
    "    pdf.set_font(\"Arial\", 'B', 10) \n",
    "    pdf.cell(35, 10, metric, border=1, align=\"C\")\n",
    "    \n",
    "    pdf.set_font(\"Arial\", size=10)\n",
    "    pdf.cell(35, 10, str(sdg_counts.get(metric, 0)), border=1, align=\"C\")\n",
    "    \n",
    "    pdf.cell(35, 10, str(sa_counts.get(metric, 0)), border=1, align=\"C\")\n",
    "    \n",
    "    pdf.cell(35, 10, str(sdg_exclusivos.get(metric, 0)), border=1, align=\"C\")\n",
    "    \n",
    "    pdf.cell(35, 10, str(sa_exclusivos.get(metric, 0)), border=1, align=\"C\")\n",
    "    \n",
    "    pdf.cell(20, 10, str(equals_counts.get(metric, 0)), border=1, align=\"C\")\n",
    "    pdf.ln()\n",
    "\n",
    "pdf.ln(5)\n",
    "pdf.set_font(\"Arial\", 'B', 10)\n",
    "pdf.cell(40, 10, \"Métrica\", border=1, align=\"C\")\n",
    "pdf.cell(40, 10, \"SDG\", border=1, align=\"C\")\n",
    "pdf.cell(40, 10, \"SA\", border=1, align=\"C\")\n",
    "pdf.ln()\n",
    "for chave in metricas_sdg.keys():\n",
    "    pdf.set_font(\"Arial\", 'B', 10)\n",
    "    pdf.cell(40, 10, chave, border=1, align=\"C\")\n",
    "    \n",
    "    pdf.set_font(\"Arial\", size=10)\n",
    "    pdf.cell(40, 10, str(metricas_sdg[chave]), border=1, align=\"C\")\n",
    "    pdf.cell(40, 10, str(metricas_sa[chave]), border=1, align=\"C\")\n",
    "    pdf.ln()\n",
    "\n",
    "pdf.image(venn_file, x=10, y=pdf.get_y(), w=150)\n",
    "\n",
    "pdf.output(\"output/results/relatorio_completo.pdf\")\n",
    "\n",
    "print(\"Relatório e diagrama de Venn salvos com sucesso em 'output/results/relatorio_completo.pdf'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
